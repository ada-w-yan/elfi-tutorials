{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is generated from a [Jupyter](http://jupyter.org/) notebook that can be found [here](https://github.com/elfi-dev/notebooks). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOLFI for the daycare example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim: to see how the tuning parameters acq_noise_var and update_interval affect performance of BOLFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 2\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set an arbitrary global seed to keep the randomly generated quantities the same\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "import elfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generated observations with true parameters t1: 3.6, t2: 0.600, t3: 0.1, \n"
     ]
    }
   ],
   "source": [
    "from elfi.examples import daycare\n",
    "model = daycare.get_model(seed_obs=seed)\n",
    "#true_params = [3.6, 0.6, 0.1]\n",
    "# priors.append(elfi.Prior('uniform', 0, 11, model=m, name='t1'))\n",
    "# priors.append(elfi.Prior('uniform', 0, 2, model=m, name='t2'))\n",
    "# priors.append(elfi.Prior('uniform', 0, 1, model=m, name='t3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_d = elfi.Operation(np.log, model['d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As BOLFI is a more advanced inference method, its interface is also a bit more involved as compared to for example rejection sampling. But not much: Using the same graphical model as earlier, the inference could begin by defining a Gaussian process (GP) model, for which ELFI uses the [GPy](https://sheffieldml.github.io/GPy/) library. This could be given as an `elfi.GPyRegression` object via the keyword argument `target_model`. In this case, we are happy with the default that ELFI creates for us when we just give it each parameter some `bounds` as a dictionary.\n",
    "\n",
    "Other notable arguments include the `initial_evidence`, which gives the number of initialization points sampled straight from the priors before starting to optimize the acquisition of points, `update_interval` which defines how often the GP hyperparameters are optimized, and `acq_noise_var` which defines the diagonal covariance of noise added to the acquired points. Note that in general BOLFI does not benefit from a `batch_size` higher than one, since the acquisition surface is updated after each batch (especially so if the noise is 0!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi = elfi.BOLFI(log_d, batch_size=1, initial_evidence=20, update_interval=10, \n",
    "                   bounds={'t1':(0, 11), 't2':(0, 2), 't3':(0, 1)}, acq_noise_var=0.1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may have some samples readily available. You could then initialize the GP model with a dictionary of previous results by giving `initial_evidence=result.outputs`.\n",
    "\n",
    "The BOLFI class can now try to `fit` the surrogate model (the GP) to the relationship between parameter values and the resulting discrepancies. We'll request only 100 evidence points (including the `initial_evidence` defined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elfi.methods.inference.bolfi:BOLFI: Fitting the surrogate model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress [==================================================] 100.0% Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elfi.methods.posteriors:Using optimized minimum value (-3.1782) of the GP discrepancy mean function as a threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 12s, sys: 195 ms, total: 10min 13s\n",
      "Wall time: 10min 18s\n"
     ]
    }
   ],
   "source": [
    "%time post = bolfi.fit(n_evidence=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Name : GP regression\n",
       "Objective : 226.49250335260248\n",
       "Number of Parameters : 4\n",
       "Number of Optimization Parameters : 4\n",
       "Updates : True\n",
       "Parameters:\n",
       "  \u001b[1mGP_regression.         \u001b[0;0m  |                   value  |  constraints  |      priors    \n",
       "  \u001b[1msum.rbf.variance       \u001b[0;0m  |      0.5822645575495805  |      +ve      |  Ga(0.00014, 1)\n",
       "  \u001b[1msum.rbf.lengthscale    \u001b[0;0m  |      0.2036598643441625  |      +ve      |    Ga(3.7, 1)  \n",
       "  \u001b[1msum.bias.variance      \u001b[0;0m  |     0.35323146351618473  |      +ve      |  Ga(3.6e-05, 1)\n",
       "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  1.3268833713003107e-05  |      +ve      |                "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolfi.target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculated free_dims [0 1 2] from visible_dims None and fixed_dims [] is neither 1D nor 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbolfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/venv-3.10.4_no_scipy/lib/python3.10/site-packages/GPy/plotting/gpy_plot/gp_plots.py:324\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(self, plot_limits, fixed_inputs, resolution, plot_raw, apply_link, which_data_ycols, which_data_rows, visible_dims, levels, samples, samples_likelihood, lower, upper, plot_data, plot_inducing, plot_density, predict_kw, projection, legend, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mConvenience function for plotting the fit of a GP.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m:param bool legend: convenience, whether to put a legend on the plot or not.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m X \u001b[38;5;241m=\u001b[39m get_x_y_var(\u001b[38;5;28mself\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 324\u001b[0m helper_data \u001b[38;5;241m=\u001b[39m \u001b[43mhelper_for_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_limits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m xmin, xmax \u001b[38;5;241m=\u001b[39m helper_data[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m    326\u001b[0m free_dims \u001b[38;5;241m=\u001b[39m helper_data[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/venvs/venv-3.10.4_no_scipy/lib/python3.10/site-packages/GPy/plotting/gpy_plot/plot_util.py:137\u001b[0m, in \u001b[0;36mhelper_for_plot_data\u001b[0;34m(self, X, plot_limits, visible_dims, fixed_inputs, resolution)\u001b[0m\n\u001b[1;32m    135\u001b[0m         Xgrid[:,i] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculated free_dims \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m from visible_dims \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and fixed_dims \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is neither 1D nor 2D\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(free_dims, visible_dims, fixed_dims))\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fixed_dims, free_dims, Xgrid, x, y, xmin, xmax, resolution\n",
      "\u001b[0;31mTypeError\u001b[0m: calculated free_dims [0 1 2] from visible_dims None and fixed_dims [] is neither 1D nor 2D"
     ]
    }
   ],
   "source": [
    "# bolfi.target_model._gp.plot() can't plot for 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful to see the acquired parameter values and the resulting discrepancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.plot_state();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolfi.plot_discrepancy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be an unnecessarily high number of points at parameter bounds. These could probably be decreased by lowering the covariance of the noise added to acquired points, defined by the optional `acq_noise_var` argument for the BOLFI constructor. Another possibility could be to [add virtual derivative observations at the borders](https://arxiv.org/abs/1704.00963), though not yet implemented in ELFI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOLFI Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2 = bolfi.extract_posterior(-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post.plot(logpdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, samples from the posterior can be acquired with an MCMC sampler. By default it runs 4 chains, and half of the requested samples are spent in adaptation/warmup. Note that depending on the smoothness of the GP approximation, the number of priors, their gradients etc., **this may be slow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time result_BOLFI = bolfi.sample(1000, info_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cannot sample from the posterior? to be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI.plot_traces();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black vertical lines indicate the end of warmup, which by default is half of the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BOLFI.plot_marginals();"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
